{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc92ec7-6c53-418e-bd13-464da756f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 0) MASTER SANITY CHECK (la funci√≥n)\n",
    "# ============================================================\n",
    "def sanity_check_tortuous_vs_nontortuous(\n",
    "    edges,\n",
    "    r_edge,\n",
    "    edge_length,\n",
    "    points_by_edge,\n",
    "    r_point,\n",
    "    lengths2_by_edge,\n",
    "    tol=1e-6,\n",
    "):\n",
    "    print(\"\\n==============================\")\n",
    "    print(\" SANITY CHECK TORTUOUS VS NON \")\n",
    "    print(\"==============================\\n\")\n",
    "\n",
    "    ratios_length = []\n",
    "    diff_r_mean = []\n",
    "    diff_r_median = []\n",
    "    bad_edges = []\n",
    "\n",
    "    # Para global stats\n",
    "    D_edge = []\n",
    "    D_tort_mean = []\n",
    "    L_edge_all = []\n",
    "    L2_all = []\n",
    "\n",
    "    skipped_no_pts = 0\n",
    "    skipped_missing = 0\n",
    "\n",
    "    for e in edges:\n",
    "        if e not in points_by_edge or e not in lengths2_by_edge or e not in r_edge or e not in edge_length:\n",
    "            skipped_missing += 1\n",
    "            continue\n",
    "\n",
    "        pts = points_by_edge[e]\n",
    "        if pts is None or len(pts) < 2:\n",
    "            skipped_no_pts += 1\n",
    "            continue\n",
    "\n",
    "        r_pts = np.array([r_point[p] for p in pts], dtype=float)\n",
    "        r_e = float(r_edge[e])\n",
    "\n",
    "        r_mean = float(np.mean(r_pts))\n",
    "        r_median = float(np.median(r_pts))\n",
    "\n",
    "        diff_r_mean.append(r_mean - r_e)\n",
    "        diff_r_median.append(r_median - r_e)\n",
    "\n",
    "        L_edge = float(edge_length[e])\n",
    "        L2 = float(np.sum(lengths2_by_edge[e]))\n",
    "\n",
    "        if L2 + tol < L_edge:\n",
    "            bad_edges.append(e)\n",
    "\n",
    "        ratios_length.append(L2 / L_edge if L_edge > 0 else np.nan)\n",
    "\n",
    "        D_edge.append(2.0 * r_e)\n",
    "        D_tort_mean.append(2.0 * r_mean)\n",
    "        L_edge_all.append(L_edge)\n",
    "        L2_all.append(L2)\n",
    "\n",
    "    D_edge = np.array(D_edge, dtype=float)\n",
    "    D_tort_mean = np.array(D_tort_mean, dtype=float)\n",
    "    L_edge_all = np.array(L_edge_all, dtype=float)\n",
    "    L2_all = np.array(L2_all, dtype=float)\n",
    "    ratios_length = np.array(ratios_length, dtype=float)\n",
    "\n",
    "    def safe_mean(x):\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        x = x[np.isfinite(x)]\n",
    "        return float(np.mean(x)) if len(x) else np.nan\n",
    "\n",
    "    def safe_std(x):\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        x = x[np.isfinite(x)]\n",
    "        return float(np.std(x)) if len(x) else np.nan\n",
    "\n",
    "    D_edge_lenw = (np.sum(D_edge * L_edge_all) / np.sum(L_edge_all)) if np.sum(L_edge_all) > 0 else np.nan\n",
    "    D_tort_lenw = (np.sum(D_tort_mean * L2_all) / np.sum(L2_all)) if np.sum(L2_all) > 0 else np.nan\n",
    "\n",
    "    print(\"0Ô∏è‚É£ COUNTS\")\n",
    "    print(f\"Edges provided              : {len(edges)}\")\n",
    "    print(f\"Edges skipped (missing data): {skipped_missing}\")\n",
    "    print(f\"Edges skipped (no pts)      : {skipped_no_pts}\")\n",
    "    print(f\"Edges analyzed              : {len(D_edge)}\\n\")\n",
    "\n",
    "    print(\"1Ô∏è‚É£ RADIUS CONSISTENCY (edge vs point)\")\n",
    "    print(f\"Mean(r_pts) - r_edge   : mean={safe_mean(diff_r_mean):.6f}  std={safe_std(diff_r_mean):.6f}\")\n",
    "    print(f\"Median(r_pts) - r_edge : mean={safe_mean(diff_r_median):.6f}  std={safe_std(diff_r_median):.6f}\\n\")\n",
    "\n",
    "    print(\"2Ô∏è‚É£ LENGTH CONSISTENCY\")\n",
    "    print(f\"mean(L2/L_edge) = {safe_mean(ratios_length):.6f}\")\n",
    "    print(f\"min(L2/L_edge)  = {np.nanmin(ratios_length):.6f}\")\n",
    "    print(f\"max(L2/L_edge)  = {np.nanmax(ratios_length):.6f}\")\n",
    "    print(f\"Edges with L2 < L_edge : {len(bad_edges)}\\n\")\n",
    "\n",
    "    print(\"3Ô∏è‚É£ DIAMETER COMPARISON (unweighted)\")\n",
    "    print(f\"Non-tortuous (edge mean)        : {safe_mean(D_edge):.6f} ¬µm\")\n",
    "    print(f\"Tortuous (mean of per-edge mean): {safe_mean(D_tort_mean):.6f} ¬µm\\n\")\n",
    "\n",
    "    print(\"4Ô∏è‚É£ LENGTH-WEIGHTED DIAMETER\")\n",
    "    print(f\"Non-tortuous (length-weighted)  : {D_edge_lenw:.6f} ¬µm\")\n",
    "    print(f\"Tortuous (length2-weighted)     : {D_tort_lenw:.6f} ¬µm\\n\")\n",
    "\n",
    "    print(\"üß† INTERPRETATION HINTS\")\n",
    "    if abs(safe_mean(diff_r_mean)) > 1e-3:\n",
    "        print(\"‚ö†Ô∏è r_edge ‚â† mean(r_pts) (bias sistem√°tico) ‚Üí DEFINICI√ìN distinta o mapeo edge‚Üîpolyline mal.\")\n",
    "    if len(bad_edges) > 0:\n",
    "        print(\"‚ùå Hay edges con L2 < L_edge ‚Üí BUG geom√©trico / lengths2 mal construidas.\")\n",
    "    if np.isfinite(D_edge_lenw) and np.isfinite(D_tort_lenw) and abs(D_edge_lenw - D_tort_lenw) > 1e-3:\n",
    "        print(\"‚ö†Ô∏è Cambia al ponderar por longitud ‚Üí EFECTO de weighting/tortuosidad (no necesariamente calibre).\")\n",
    "\n",
    "    print(\"\\n==============================\\n\")\n",
    "\n",
    "    return {\n",
    "        \"diff_r_mean\": diff_r_mean,\n",
    "        \"diff_r_median\": diff_r_median,\n",
    "        \"length_ratios\": ratios_length,\n",
    "        \"bad_edges\": bad_edges,\n",
    "        \"D_edge_lenw\": D_edge_lenw,\n",
    "        \"D_tort_lenw\": D_tort_lenw,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Helpers: carga + inspecci√≥n + selecci√≥n autom√°tica attrs\n",
    "# ============================================================\n",
    "def load_pkl(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def print_data_summary(name, data):\n",
    "    print(f\"\\n================ {name} SUMMARY ================\")\n",
    "    print(\"Top-level keys:\", sorted(list(data.keys())))\n",
    "\n",
    "    G = data.get(\"graph\", None)\n",
    "    if G is None:\n",
    "        print(\"‚ùå data['graph'] no existe\")\n",
    "        return\n",
    "\n",
    "    print(f\"Graph: v={G.vcount()}  e={G.ecount()}\")\n",
    "    print(\"Vertex attributes:\", G.vs.attributes())\n",
    "    print(\"Edge attributes  :\", G.es.attributes())\n",
    "\n",
    "def pick_first_existing_attr(attr_list, candidates):\n",
    "    for c in candidates:\n",
    "        if c in attr_list:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def build_edge_map_from_attr(G, attr_name):\n",
    "    \"\"\"Devuelve dict {edge_id: value} para un atributo de edge.\"\"\"\n",
    "    out = {}\n",
    "    for e in G.es:\n",
    "        out[e.index] = e[attr_name]\n",
    "    return out\n",
    "\n",
    "def ensure_edge_ids_consistent(keys_a, keys_b, label_a=\"A\", label_b=\"B\"):\n",
    "    sa, sb = set(keys_a), set(keys_b)\n",
    "    inter = sa & sb\n",
    "    only_a = sa - sb\n",
    "    only_b = sb - sa\n",
    "    print(f\"\\n--- EdgeID consistency {label_a} vs {label_b} ---\")\n",
    "    print(f\"Common edges: {len(inter)}\")\n",
    "    print(f\"Only {label_a}: {len(only_a)}\")\n",
    "    print(f\"Only {label_b}: {len(only_b)}\")\n",
    "    return inter, only_a, only_b\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) CONFIG: pon aqu√≠ tus dos archivos\n",
    "# ============================================================\n",
    "p_non  = \"/home/admin/Ana/MicroBrain/output/graph_18_OutGeom.pkl\"\n",
    "p_tort = \"/home/admin/Ana/MicroBrain/18_igraph.pkl\"  # <-- cambia al nombre real\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) LOAD + INSPECT\n",
    "# ============================================================\n",
    "data_non  = load_pkl(p_non)\n",
    "data_tort = load_pkl(p_tort)\n",
    "\n",
    "print_data_summary(\"NON-TORTUOUS\", data_non)\n",
    "print_data_summary(\"TORTUOUS\", data_tort)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Extract graphs\n",
    "# ============================================================\n",
    "G_non  = data_non[\"graph\"]\n",
    "G_tort = data_tort[\"graph\"]\n",
    "\n",
    "# ============================================================\n",
    "# 5) Detect edge radius / length attributes en NON (source of truth)\n",
    "# ============================================================\n",
    "edge_attrs_non = G_non.es.attributes()\n",
    "\n",
    "radius_candidates = [\"r_edge\", \"radius_edge\", \"radius\", \"r\", \"rad\", \"radius_um\", \"r_um\", \"diameter\", \"diam\", \"diam_um\"]\n",
    "length_candidates = [\"length\", \"len\", \"length_um\", \"L\", \"edge_length\", \"length_geom\", \"length_eucl\"]\n",
    "\n",
    "rad_attr = pick_first_existing_attr(edge_attrs_non, radius_candidates)\n",
    "len_attr = pick_first_existing_attr(edge_attrs_non, length_candidates)\n",
    "\n",
    "print(\"\\n================ ATTRIBUTE PICKING ================\")\n",
    "print(\"NON edge attrs:\", edge_attrs_non)\n",
    "print(\"Picked radius attr:\", rad_attr)\n",
    "print(\"Picked length attr:\", len_attr)\n",
    "\n",
    "if rad_attr is None:\n",
    "    raise KeyError(\"No encuentro atributo de radio en edges del NON. Mira la lista 'Edge attributes' e indica el correcto.\")\n",
    "if len_attr is None:\n",
    "    raise KeyError(\"No encuentro atributo de length en edges del NON. Mira la lista 'Edge attributes' e indica el correcto.\")\n",
    "\n",
    "# Si detect√≥ 'diameter' como radio, lo convertimos a radio\n",
    "is_diameter = rad_attr in [\"diameter\", \"diam\", \"diam_um\"]\n",
    "\n",
    "r_edge = build_edge_map_from_attr(G_non, rad_attr)\n",
    "if is_diameter:\n",
    "    r_edge = {k: float(v) / 2.0 for k, v in r_edge.items()}\n",
    "\n",
    "edge_length = build_edge_map_from_attr(G_non, len_attr)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Detect tortuous structures: points_by_edge, radii_geom, lengths2_by_edge\n",
    "# ============================================================\n",
    "print(\"\\n================ TORTUOUS KEYS PICKING ================\")\n",
    "tkeys = data_tort.keys()\n",
    "print(\"TORT top keys:\", sorted(list(tkeys)))\n",
    "\n",
    "# candidatos t√≠picos\n",
    "pbe_candidates = [\"points_by_edge\", \"edge_points\", \"polyline_points_by_edge\", \"edge_to_points\"]\n",
    "rpt_candidates = [\"radii_geom\", \"radius_point\", \"r_point\", \"radii_point\", \"radius_p\", \"r_geom\"]\n",
    "l2_candidates  = [\"lengths2_by_edge\", \"lengths2\", \"seg_lengths2_by_edge\", \"lengths_tort_by_edge\"]\n",
    "\n",
    "pbe_key = pick_first_existing_attr(list(tkeys), pbe_candidates)\n",
    "rpt_key = pick_first_existing_attr(list(tkeys), rpt_candidates)\n",
    "l2_key  = pick_first_existing_attr(list(tkeys), l2_candidates)\n",
    "\n",
    "print(\"Picked points_by_edge key:\", pbe_key)\n",
    "print(\"Picked r_point key      :\", rpt_key)\n",
    "print(\"Picked lengths2 key     :\", l2_key)\n",
    "\n",
    "if pbe_key is None:\n",
    "    raise KeyError(\"No encuentro points_by_edge en TORT. Mira keys y pon el nombre correcto.\")\n",
    "if rpt_key is None:\n",
    "    raise KeyError(\"No encuentro radii por punto (radii_geom) en TORT. Mira keys y pon el nombre correcto.\")\n",
    "if l2_key is None:\n",
    "    raise KeyError(\"No encuentro lengths2_by_edge en TORT. Mira keys y pon el nombre correcto.\")\n",
    "\n",
    "points_by_edge = data_tort[pbe_key]\n",
    "r_point = data_tort[rpt_key]\n",
    "lengths2_by_edge = data_tort[l2_key]\n",
    "\n",
    "# Normaliza: por si vienen como listas indexadas por edge_id en vez de dict\n",
    "def normalize_edge_container(x, name):\n",
    "    if isinstance(x, dict):\n",
    "        return x\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        # asumimos que x[edge_id] existe\n",
    "        return {i: x[i] for i in range(len(x))}\n",
    "    raise TypeError(f\"{name} tiene tipo raro: {type(x)}\")\n",
    "\n",
    "points_by_edge = normalize_edge_container(points_by_edge, \"points_by_edge\")\n",
    "lengths2_by_edge = normalize_edge_container(lengths2_by_edge, \"lengths2_by_edge\")\n",
    "\n",
    "# ============================================================\n",
    "# 7) Edge ID consistency check\n",
    "# ============================================================\n",
    "common_edges, only_non, only_tort = ensure_edge_ids_consistent(\n",
    "    r_edge.keys(), points_by_edge.keys(), \"NON(r_edge)\", \"TORT(points_by_edge)\"\n",
    ")\n",
    "common_edges2, _, _ = ensure_edge_ids_consistent(\n",
    "    edge_length.keys(), lengths2_by_edge.keys(), \"NON(edge_length)\", \"TORT(lengths2_by_edge)\"\n",
    ")\n",
    "\n",
    "edges = sorted(list(common_edges & common_edges2))\n",
    "print(f\"\\n‚úÖ Using {len(edges)} common edges for sanity check.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) RUN SANITY CHECK\n",
    "# ============================================================\n",
    "out = sanity_check_tortuous_vs_nontortuous(\n",
    "    edges=edges,\n",
    "    r_edge=r_edge,\n",
    "    edge_length=edge_length,\n",
    "    points_by_edge=points_by_edge,\n",
    "    r_point=r_point,\n",
    "    lengths2_by_edge=lengths2_by_edge,\n",
    ")\n",
    "\n",
    "# Si quieres ver cu√°les son los edges malos:\n",
    "if len(out[\"bad_edges\"]) > 0:\n",
    "    print(\"First 20 bad_edges:\", out[\"bad_edges\"][:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713bf31c-c496-45fb-9fc8-f8532b7c671b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-base)",
   "language": "python",
   "name": "conda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
