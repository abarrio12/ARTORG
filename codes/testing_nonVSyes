import pickle
import numpy as np
import igraph as ig

# -----------------------------
# Loaders
# -----------------------------
def load_any(path):
    obj = pickle.load(open(path, "rb"))
    if isinstance(obj, ig.Graph):
        return {"graph": obj}
    if isinstance(obj, dict):
        if "graph" in obj and isinstance(obj["graph"], ig.Graph):
            return obj
        # por si viene con graph en otra key
        for k, v in obj.items():
            if isinstance(v, ig.Graph):
                obj = dict(obj)
                obj["graph"] = v
                return obj
        raise KeyError(f"{path}: dict pero no encuentro ningún igraph.Graph dentro.")
    raise TypeError(f"{path}: tipo no soportado: {type(obj)}")

def to_np_coords(coords):
    C = np.asarray(coords, dtype=float)
    if C.ndim != 2 or C.shape[1] != 3:
        raise ValueError(f"coords tiene shape rara: {C.shape} (esperaba Nx3)")
    return C

# -----------------------------
# Core geometry
# -----------------------------
def polyline_length(P):
    """P: (n,3)"""
    if len(P) < 2:
        return 0.0
    d = np.linalg.norm(P[1:] - P[:-1], axis=1)
    return float(np.sum(d))

# -----------------------------
# Main sanity checks
# -----------------------------
def run_all_tests(p_non, p_tort, tol_radius=1e-6, tol_len=1e-4, max_edges_debug=5):
    data_non = load_any(p_non)
    data_tort = load_any(p_tort)

    G_non = data_non["graph"]
    G_tort = data_tort["graph"]

    print("\n========== BASIC CHECKS ==========")
    print("NON:  v,e =", G_non.vcount(), G_non.ecount())
    print("TORT: v,e =", G_tort.vcount(), G_tort.ecount())

    if G_non.ecount() != G_tort.ecount():
        print("❌ ecount distinto → no puedes comparar edge-by-edge directo.")
        return

    # ---------
    # 1) Radius/diameter invariance (edge attrs)
    # ---------
    r_non = np.asarray(G_non.es["radius"], dtype=float)
    r_tor = np.asarray(G_tort.es["radius"], dtype=float)
    d_non = np.asarray(G_non.es["diameter"], dtype=float)
    d_tor = np.asarray(G_tort.es["diameter"], dtype=float)

    dr = r_tor - r_non
    dd = d_tor - d_non

    print("\n========== 1) RADIUS / DIAMETER ==========")
    print(f"radius diff: mean={dr.mean():.6g}  std={dr.std():.6g}  maxabs={np.max(np.abs(dr)):.6g}")
    print(f"diam   diff: mean={dd.mean():.6g}  std={dd.std():.6g}  maxabs={np.max(np.abs(dd)):.6g}")

    n_bad_r = int(np.sum(np.abs(dr) > tol_radius))
    n_bad_d = int(np.sum(np.abs(dd) > 2*tol_radius))
    print(f"edges with |Δradius|>{tol_radius}: {n_bad_r} / {len(r_non)}")
    print(f"edges with |Δdiam|>{2*tol_radius}: {n_bad_d} / {len(d_non)}")

    # Debug edges where radius differs
    if n_bad_r > 0:
        idx = np.where(np.abs(dr) > tol_radius)[0][:max_edges_debug]
        print("Examples (edge_id, r_non, r_tort, Δr):")
        for e in idx:
            print(e, r_non[e], r_tor[e], dr[e])

    # ---------
    # 2) Tortuosity identity: tortuosity ?= length_tortuous / length
    # ---------
    L = np.asarray(G_tort.es["length"], dtype=float)          # straight (según tu edge attr)
    Lt = np.asarray(G_tort.es["length_tortuous"], dtype=float)
    tau = np.asarray(G_tort.es["tortuosity"], dtype=float)

    # evita división por cero
    ratio = np.full_like(L, np.nan, dtype=float)
    mask = L > 0
    ratio[mask] = Lt[mask] / L[mask]
    dtau = tau - ratio

    print("\n========== 2) TORTUOSITY CONSISTENCY ==========")
    print(f"tortuosity - (Lt/L): mean={np.nanmean(dtau):.6g}  std={np.nanstd(dtau):.6g}  maxabs={np.nanmax(np.abs(dtau)):.6g}")
    n_bad_tau = int(np.sum(np.abs(dtau[np.isfinite(dtau)]) > tol_len))
    print(f"edges with |Δtau|>{tol_len}: {n_bad_tau} / {np.sum(np.isfinite(dtau))}")

    # ---------
    # 3) Recompute tortuous length from coords + geom_start/end
    #    (esto es tu “sum(lengths2) == length(edge)” pero reconstruido)
    # ---------
    print("\n========== 3) RECOMPUTE Lt FROM COORDS ==========")

    if "coords" not in data_tort:
        print("❌ TORT dict no tiene key 'coords' → no puedo recomputar Lt por geometría.")
        return

    # coords global de polylines concatenadas
    C = to_np_coords(data_tort["coords"])

    # índices por edge
    if "geom_start" not in G_tort.es.attributes() or "geom_end" not in G_tort.es.attributes():
        print("❌ TORT edges no tienen geom_start/geom_end → no puedo trocear coords por edge.")
        return

    gs = np.asarray(G_tort.es["geom_start"], dtype=int)
    ge = np.asarray(G_tort.es["geom_end"], dtype=int)

    Lt_recomp = np.zeros(G_tort.ecount(), dtype=float)
    bad_geom = []

    for e in range(G_tort.ecount()):
        s, t = gs[e], ge[e]
        if not (0 <= s < t <= len(C)):
            bad_geom.append(e)
            Lt_recomp[e] = np.nan
            continue
        P = C[s:t]
        Lt_recomp[e] = polyline_length(P)

    if bad_geom:
        print(f"❌ Edges con geom_start/end fuera de rango: {len(bad_geom)} (ej: {bad_geom[:10]})")

    dLt = Lt_recomp - Lt
    print(f"Lt_recomputed - Lt_attr: mean={np.nanmean(dLt):.6g}  std={np.nanstd(dLt):.6g}  maxabs={np.nanmax(np.abs(dLt)):.6g}")
    n_bad_Lt = int(np.sum(np.abs(dLt[np.isfinite(dLt)]) > tol_len))
    print(f"edges with |ΔLt|>{tol_len}: {n_bad_Lt} / {np.sum(np.isfinite(dLt))}")

    if n_bad_Lt > 0:
        idx = np.where(np.abs(dLt) > tol_len)[0][:max_edges_debug]
        print("Examples (edge_id, Lt_attr, Lt_recomp, Δ):")
        for e in idx:
            print(e, Lt[e], Lt_recomp[e], dLt[e])

    # ---------
    # 4) Optional: recompute straight length from endpoints of the polyline slice
    # ---------
    print("\n========== 4) OPTIONAL: RECOMPUTE STRAIGHT FROM SLICE ENDPOINTS ==========")
    L_recomp = np.zeros(G_tort.ecount(), dtype=float)

    for e in range(G_tort.ecount()):
        s, t = gs[e], ge[e]
        if not (0 <= s < t <= len(C)):
            L_recomp[e] = np.nan
            continue
        P = C[s:t]
        L_recomp[e] = float(np.linalg.norm(P[-1] - P[0]))

    dL = L_recomp - L
    print(f"L_recomputed(endpoints) - L_attr: mean={np.nanmean(dL):.6g}  std={np.nanstd(dL):.6g}  maxabs={np.nanmax(np.abs(dL)):.6g}")
    n_bad_L = int(np.sum(np.abs(dL[np.isfinite(dL)]) > tol_len))
    print(f"edges with |ΔL|>{tol_len}: {n_bad_L} / {np.sum(np.isfinite(dL))}")

    print("\n✅ DONE.\n")


# -----------------------------
# PUT YOUR PATHS HERE
# -----------------------------
p_non  = "/home/admin/Ana/MicroBrain/18_igraph.pkl"
p_tort = "/home/admin/Ana/MicroBrain/output/graph_18_OutGeom.pkl"  # ajusta si hace falta

run_all_tests(p_non, p_tort, tol_radius=1e-6, tol_len=1e-4)
